<html>

<head>
<link rel="shortcut icon" type="image/ico" href="favicon.ico" />
<link rel="stylesheet" type="text/css" href="style.css">

<title>Michael Wray - PhD Student - University of Bristol</title>
</head>

<body topmargin="15" leftmargin="15">


    <div id="blueBar">
        <h1>Improving Classification by Improving Labelling: Introducing Probabilistic Multi-Label Object Interaction Recognition</h1>
        <h2>March 2017</h2>
    </div>
    <h4> Back to <a href="index.html">Home</a></h4>

    <p><a href="http://mwray.github.io">Michael Wray</a>, <a href="http://www.davidemoltisanti.com/research">Davide Moltisanti</a>, <a href="http://www.cs.bris.ac.uk/~wmayol/">Walterio Mayol-Cuevas</a>, <a href="http://www.cs.bris.ac.uk/~damen">Dima Damen</a></p>

        <p><img src="ICIL/magic.png" alt="Overview" width=600/></p>


        <p>
        For the task of action recognition semantic ambiguities between verbs can
        result in overlaps between classes. Because of this standard classification
        techniques are unable to correctly learn valid verb labels for each video.
        </p>
        
        <p>
        Given a video segment containing an object interaction we model the
        probability of a verb - out of a list of verbs - being chosen by human
        annotators as a correct label for the video.
        </p>
        
        <p>
        We use a two-stream CNN and test a probabilistic classifier on two public
        datasets, comprising of 1405 video sequences which we label, and outperform
        conventional single-label classification by 11% and 6% on the two datasets
        respectively. We also show that by learning probabilities the method is able
        outperform majority voting and enables discovery of co-occurring labels.
        </p>
        
        <h3>Publication:</h3>
        Improving Classification by Improving Labelling: Introducing Probabilistic Multi-Label Object Interaction Recognition, Michael Wray, Davide Moltisanti, Walterio Mayol-Cuevas and Dima Damen (2017).
        <b>Link:</b> <a href = "https://arxiv.org/abs/1703.08338">Arxiv</a>.
        

        <h3>Video:</h3>
        <p><iframe width="560" height="315" src="https://www.youtube.com/embed/70KxhrZ0DhM" frameborder="0" allowfullscreen></iframe></p>

        <h3>Results</h3>
        Example results when looking at the top 5 ground truth and predicted verbs:
        <p><img src="ICIL/results.png" alt="Results" width=900/></p>

        <h3>Dataset:</h3>
        <a href="http://www.cs.bris.ac.uk/~damen/BEOID/">Bristol Egocentric Object Interactions Dataset</a>
        
        
        <h4> Back to <a href="index.html">Home</a></h4>

</body>
</html>

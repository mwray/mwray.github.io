<html>

<head>
<link rel="shortcut icon" type="image/ico" href="favicon.ico" />
<link rel="stylesheet" type="text/css" href="style.css">

<title>Michael Wray - PhD Student - University of Bristol</title>
</head>

<body topmargin="15" leftmargin="15">

    <div id="blueBar">
        <h1>SEMBED: Semantic Embedding of Egocentric Action Videos</h1>
        <h2>July 2016</h2>
    </div>
        <h4> Back to <a href="index.html">Home</a></h4>

        <p><a href="http://mwray.github.io">Michael Wray</a>*, <a href="http://www.davidemoltisanti.com/research">Davide Moltisanti</a>*, <a href="http://www.cs.bris.ac.uk/~wmayol/">Walterio Mayol-Cuevas</a>, <a href="http://www.cs.bris.ac.uk/~damen">Dima Damen</a></p>
        <p><i>* Denotes equal contribution</i></p>

        <h3> Description </h3>
        <p>
        Egocentric Action Recognition has largely been performed on datasets where
        annotators had a choice from a finite set of semantically distinct verbs. 
        </p>
        
        <p>
        When allowed free choice over both the verb chosen to describe an action and
        the temporal boundaries the resulting dataset contains a wide variety of
        different labels. Whilst these labels are diverse we treat them all as
        correct labels. Standard one vs. all classifying techniques, such as SVM, 
        are unable to deal with the ambiguities introduced by the free annotations 
        and so a graphical approach is introduced. 
        </p>
        
        <p>
        We present SEMBED, a method which is capable of dealing with the ambiguity
        within the dataset by embedding videos in a Semantic Visual Graph. Multiple
        state-of-the-art features have been tested (in the form of Improved Dense 
        Trajectories and Overfeat CNN) along with Bag of (Visual) Words and Fisher
        Vectors as encoding methods. We find that SEMBED using the notion of 
        embedding videos in a graph that are linked visually and/or semantically is
        able to beat SVM by more than 5%.
        </p>
        
        <h3>Publication:</h3>
        <p>Michael Wray, Davide Moltisanti, Walterio Mayol-Cuevas and Dima Damen 
        (2016). SEMBED: Semantic Embedding of Egocentric Action Videos. 
        Egocentric Perception, Interaction and Computing Workshop ECCV 2016, 
        Amsterdam, The Netherlands.
        <a href = "http://arxiv.org/abs/1607.08414">Arxiv</a>.</p>
        
        <h3>Dataset:</h3>
        <a href="http://www.cs.bris.ac.uk/~Damen/BEOID/">Bristol Egocentric Object Interactions Dataset</a>
        
        <h3>Video:</h3>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/6bDDTIJUuic" frameborder="0" allowfullscreen></iframe>


        <h4> Back to <a href="index.html">Home</a></h4>
</body>
</html>
